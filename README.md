# ğŸ“¡ Telecom Customer Churn Prediction â€” Real-Time ML App

## ğŸ“Œ Overview

This project implements a real-time customer churn prediction system for the telecommunications sector.

The application allows users to input customer characteristics through a web form and receive:

- ğŸ”¢ **Predicted churn probability**
- ğŸš¦ **Risk classification** (Low / Medium / High)
- ğŸ’¾ **Automatic storage** of prediction logs in PostgreSQL

The system is fully containerized using Docker and follows a clean production-style architecture.

---

## ğŸ— Architecture

```
User (Browser)
        â†“
Streamlit App (Frontend + Inference)
        â†“
Serialized ML Pipeline (churn_pipeline.pkl)
        â†“
PostgreSQL (Prediction Logs Storage)
```

### Components

| Component | Role |
|---|---|
| **Streamlit** | User interface + model inference |
| **Scikit-learn Pipeline** | Preprocessing + Gradient Boosting classifier |
| **PostgreSQL** | Stores prediction history |
| **Docker & Docker Compose** | Containerized deployment |

---

## ğŸ§  Machine Learning Model

The predictive system uses a scikit-learn `Pipeline` containing:

- `StandardScaler` (numerical features)
- `OneHotEncoder` (categorical features)
- `GradientBoostingClassifier`

The entire preprocessing and model logic is serialized into:

```
model/churn_pipeline.pkl
```

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”‚   â””â”€â”€ customer_churn_telecom_analysis.ipynb
â”œâ”€â”€ db
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ model
    â””â”€â”€ churn_pipeline.pkl
```

---

## ğŸš€ How to Run the Project

### 1. Configure Environment Variables

Copy the example file and fill the following values:

```bash
cp .env.example .env
```

The `.env` should look like this:

```env
# PostgreSQL
DB_NAME=churn_db
DB_USER=postgres
DB_PASSWORD=postgres
```

> âš ï¸ Never commit `.env` file. It is already listed in `.gitignore`.

### 2. Build and Run

From the root directory:

```bash
docker compose up --build
```

### 3. Access the Application

Open in your browser:

```
http://localhost:8501
```

---

## ğŸ“Š Risk Classification Logic

| Probability | Risk Level |
|---|---|
| â‰¥ 70% | ğŸ”´ High Risk |
| 40% â€“ 69% | ğŸŸ  Medium Risk |
| < 40% | ğŸŸ¢ Low Risk |


---

## ğŸ’¾ Database Logging

Each prediction is stored in PostgreSQL with:

- Input customer attributes
- Predicted probability
- Risk level
- Timestamp

**Table:** `predictions`

This enables:

- Audit trail
- Business analytics
- Model monitoring
- Future retraining datasets

### Inspect Stored Predictions

```bash
docker exec -it churn_db psql -U postgres -d churn_db -c "SELECT id, churn_probability, risk_level, created_at FROM predictions ORDER BY id DESC LIMIT 10;"
```

---

### Stop Docker Services

When finished, stop all containers:

```bash
docker compose down
```

## ğŸ“š Technologies Used

| Technology | Version |
|---|---|
| Python | 3.12 |
| Scikit-learn | 1.6.1 |
| Joblib | 1.5.3 |
| Streamlit | latest |
| PostgreSQL | 16 |
| Docker | latest |

---

## ğŸ‘¨â€ğŸ’» Author

**Telecom Customer Churn Prediction System**  
Samuel